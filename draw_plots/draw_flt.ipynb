{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e5619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib as mpl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f63256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../results/results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c49fe4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(\n",
    "    activation = 'linear',\n",
    "    use_bias = 1,\n",
    "    target_depth = 1,\n",
    "    frozen_depth = 8,\n",
    "    init_mode = 'default',\n",
    "    width = 16,\n",
    "    exp = 'fnn',\n",
    "    pretrained = 0,\n",
    "    tune_bias = 1,\n",
    "):\n",
    "    test_loss = {}\n",
    "    if pretrained:\n",
    "        pretrained_idx = df.pretrained == 1\n",
    "    else:\n",
    "        # since there are many results with pretrained = NaN\n",
    "        # they were run before I implemented the pretrained feature in my code\n",
    "        pretrained_idx = df.pretrained != 1\n",
    "        \n",
    "    if tune_bias == 0:\n",
    "        tune_bias_idx = df.tune_bias == 0\n",
    "    else:\n",
    "        # since there are many results with tune_bias = NaN\n",
    "        # they were run before I implemented the tune_bies feature in my code\n",
    "        tune_bias_idx = df.tune_bias != 0\n",
    "        \n",
    "        \n",
    "    for method in ['sgd', 'flt']:\n",
    "        run_idx = (\n",
    "            (df.activation == activation) & \n",
    "            (df.method == method) & \n",
    "            (df.use_bias == use_bias) & \n",
    "            (df.target_depth == target_depth) & \n",
    "            (df.frozen_depth == frozen_depth) & \n",
    "            (df.init_mode == init_mode) & \n",
    "            (df.width == width) &\n",
    "            (df.exp == exp) &\n",
    "            pretrained_idx &\n",
    "            tune_bias_idx\n",
    "        )\n",
    "\n",
    "        group_df = df[run_idx].reset_index(drop = True)\n",
    "        rank_set = np.unique(group_df['rank'])\n",
    "        group_df_rank, group_df_layers = {}, {}\n",
    "        test_loss[method] = {}\n",
    "        if method == 'sgd':\n",
    "            for rank in rank_set:\n",
    "                group_df_rank[rank] = group_df[group_df['rank'] == rank]\n",
    "                min_loss_index = group_df_rank[rank]['val_loss'].idxmin()\n",
    "                row_with_min_loss = group_df_rank[rank].loc[min_loss_index]\n",
    "                test_loss[method][rank*2*width*frozen_depth] = row_with_min_loss['test_loss']\n",
    "        elif method == 'flt':\n",
    "            for last_layers in range(1, frozen_depth):\n",
    "                group_df_layers[last_layers] = group_df[group_df['last_layers'] == last_layers]\n",
    "                min_loss_index = group_df_layers[last_layers]['val_loss'].idxmin()\n",
    "                row_with_min_loss = group_df_layers[last_layers].loc[min_loss_index]\n",
    "                test_loss[method][last_layers*width**2] = row_with_min_loss['test_loss']\n",
    "        else:\n",
    "            raise notImplementError(f\"We only support sgd and ours, not {method}!\")\n",
    "        test_loss[method] = pd.Series(test_loss[method])        \n",
    "        \n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6cea5ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rows(\n",
    "    args_dict,\n",
    "):\n",
    "    idx = {}\n",
    "    for key, value in args_dict.items():\n",
    "        if value is None:\n",
    "            idx[key] = np.ones_like(df[key], dtype=bool)\n",
    "        else:\n",
    "            idx[key] = df[key] == value\n",
    "        \n",
    "    run_idx = np.ones_like(df['test_loss'], dtype=bool)\n",
    "    for key, value in idx.items():\n",
    "        run_idx = run_idx & value\n",
    "    \n",
    "    # print(f\"Selected {run_idx.sum()} runs!\")\n",
    "    \n",
    "    run_df = df[run_idx].reset_index(drop=True)   \n",
    "    return run_df\n",
    "\n",
    "def get_loss(\n",
    "    args_dict,\n",
    "):\n",
    "    run_df = get_rows(args_dict)\n",
    "\n",
    "    rank_set = np.unique(run_df['rank'])\n",
    "    seed_set = np.unique(run_df['seed'])\n",
    "    test_loss, test_loss_median = {}, {}\n",
    "    \n",
    "    frozen_depth = args_dict['frozen_depth']\n",
    "    width = args_dict['width']\n",
    "    \n",
    "    for method in ['sgd', 'flt']:\n",
    "        test_loss_median[method], test_loss[method] = {}, {}\n",
    "        group_df = run_df[run_df['method'] == method].reset_index(drop=True)   \n",
    "        if method == 'sgd':     \n",
    "            for rank in rank_set:\n",
    "                rank_df = group_df[group_df['rank'] == rank].reset_index(drop=True)\n",
    "                test_loss[method][rank], test_loss_median[method][rank]= {}, {}\n",
    "                for seed in seed_set:\n",
    "                    seed_df = rank_df[rank_df['seed'] == seed].reset_index(drop=True)        \n",
    "                    min_loss_index = seed_df['val_loss'].idxmin()\n",
    "                    row_with_min_loss = seed_df.loc[min_loss_index]\n",
    "                    test_loss[method][rank][seed] = row_with_min_loss['test_loss']\n",
    "                test_loss_median[method][rank*2*width*frozen_depth] = pd.Series(test_loss[method][rank]).median()\n",
    "\n",
    "        elif method == 'flt':\n",
    "            for last_layers in range(1, frozen_depth):\n",
    "                layer_df = group_df[group_df['last_layers'] == last_layers]\n",
    "                test_loss[method][last_layers], test_loss_median[method][last_layers] = {}, {}\n",
    "                for seed in seed_set:\n",
    "                    try:\n",
    "                        seed_df = layer_df[layer_df['seed'] == seed].reset_index(drop=True)        \n",
    "                        min_loss_index = seed_df['val_loss'].idxmin()\n",
    "                        row_with_min_loss = seed_df.loc[min_loss_index]\n",
    "                        test_loss[method][last_layers][seed] = row_with_min_loss['test_loss']\n",
    "                    except:\n",
    "                        print('there')\n",
    "                        print(last_layers, seed)\n",
    "                print(test_loss[method][last_layers][seed])\n",
    "                test_loss_median[method][last_layers*width**2] = pd.Series(test_loss[method][last_layers]).median()\n",
    "        else:\n",
    "            raise notImplementError(f\"We only support sgd and ours, not {method}!\")\n",
    "        \n",
    "    return {\n",
    "        'sgd': pd.Series(test_loss_median['sgd']), \n",
    "        'flt': pd.Series(test_loss_median['flt']),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf221d",
   "metadata": {},
   "source": [
    "## FNN Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f9734a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "activation = 'relu'\n",
    "use_bias = 1\n",
    "width = 16\n",
    "exp = 'fnn'\n",
    "init_mode = 'default'\n",
    "target_depth = 1\n",
    "frozen_depth = 8\n",
    "\n",
    "fnn_results = {}\n",
    "\n",
    "for pretrained in [0,1]:\n",
    "    fnn_results[pretrained] = get_loss({\n",
    "    'activation': activation,\n",
    "    'use_bias': use_bias,\n",
    "    'target_depth': target_depth,\n",
    "    'frozen_depth': frozen_depth,\n",
    "    'init_mode': init_mode,\n",
    "    'width': width,\n",
    "    'exp': exp,\n",
    "    'pretrained': pretrained,\n",
    "    'tune_bias': 1,\n",
    "    'rank_step': 0,\n",
    "})\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e36e8e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1             {}\n",
       "256     0.118086\n",
       "2             {}\n",
       "512     0.114395\n",
       "3             {}\n",
       "768     0.107546\n",
       "4             {}\n",
       "1024    0.106263\n",
       "5             {}\n",
       "1280    0.097921\n",
       "6             {}\n",
       "1536     0.08716\n",
       "7             {}\n",
       "1792    0.073206\n",
       "dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fnn_results[0]['flt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7d83308",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no numeric data to plot",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/lora/draw_plots/draw_flt.ipynb Cell 8\u001b[0m line \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d536b756e642d506f64227d/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/lora/draw_plots/draw_flt.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m fig\u001b[39m.\u001b[39mset_size_inches(\u001b[39m7\u001b[39m, \u001b[39m3.5\u001b[39m) \u001b[39m#exact size of the figure\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d536b756e642d506f64227d/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/lora/draw_plots/draw_flt.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m pretrained \u001b[39min\u001b[39;00m [\u001b[39m0\u001b[39m,\u001b[39m1\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d536b756e642d506f64227d/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/lora/draw_plots/draw_flt.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m     fnn_results[pretrained][\u001b[39m'\u001b[39;49m\u001b[39msgd\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mplot(ax \u001b[39m=\u001b[39;49m ax[pretrained], color \u001b[39m=\u001b[39;49m sgd_color, label \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mLoRA\u001b[39;49m\u001b[39m'\u001b[39;49m, linestyle \u001b[39m=\u001b[39;49m sgd_lt, marker \u001b[39m=\u001b[39;49m sgd_marker, linewidth \u001b[39m=\u001b[39;49m lw, markersize \u001b[39m=\u001b[39;49m sgd_ms)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d536b756e642d506f64227d/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/lora/draw_plots/draw_flt.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     fnn_results[pretrained][\u001b[39m'\u001b[39m\u001b[39mflt\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mplot(ax \u001b[39m=\u001b[39m ax[pretrained], color \u001b[39m=\u001b[39m our_color, label \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTuning Final Layers\u001b[39m\u001b[39m'\u001b[39m, linestyle \u001b[39m=\u001b[39m our_lt, marker \u001b[39m=\u001b[39m our_marker, linewidth \u001b[39m=\u001b[39m lw, markersize \u001b[39m=\u001b[39m our_ms)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a2249424d2d536b756e642d506f64227d/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/lora/draw_plots/draw_flt.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     ax[pretrained]\u001b[39m.\u001b[39mgrid(\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/anaconda3/envs/ibm/lib/python3.8/site-packages/pandas/plotting/_core.py:1000\u001b[0m, in \u001b[0;36mPlotAccessor.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    997\u001b[0m             label_name \u001b[39m=\u001b[39m label_kw \u001b[39mor\u001b[39;00m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m    998\u001b[0m             data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m label_name\n\u001b[0;32m-> 1000\u001b[0m \u001b[39mreturn\u001b[39;00m plot_backend\u001b[39m.\u001b[39;49mplot(data, kind\u001b[39m=\u001b[39;49mkind, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/anaconda3/envs/ibm/lib/python3.8/site-packages/pandas/plotting/_matplotlib/__init__.py:71\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(data, kind, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39max\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(ax, \u001b[39m\"\u001b[39m\u001b[39mleft_ax\u001b[39m\u001b[39m\"\u001b[39m, ax)\n\u001b[1;32m     70\u001b[0m plot_obj \u001b[39m=\u001b[39m PLOT_CLASSES[kind](data, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 71\u001b[0m plot_obj\u001b[39m.\u001b[39;49mgenerate()\n\u001b[1;32m     72\u001b[0m plot_obj\u001b[39m.\u001b[39mdraw()\n\u001b[1;32m     73\u001b[0m \u001b[39mreturn\u001b[39;00m plot_obj\u001b[39m.\u001b[39mresult\n",
      "File \u001b[0;32m/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/anaconda3/envs/ibm/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:450\u001b[0m, in \u001b[0;36mMPLPlot.generate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerate\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    449\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args_adjust()\n\u001b[0;32m--> 450\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_plot_data()\n\u001b[1;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_subplots()\n\u001b[1;32m    452\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_plot()\n",
      "File \u001b[0;32m/skunk-pod-storage-yzeng58-40wisc-2eedu-pvc/anaconda3/envs/ibm/lib/python3.8/site-packages/pandas/plotting/_matplotlib/core.py:635\u001b[0m, in \u001b[0;36mMPLPlot._compute_plot_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[39m# no non-numeric frames or series allowed\u001b[39;00m\n\u001b[1;32m    634\u001b[0m \u001b[39mif\u001b[39;00m is_empty:\n\u001b[0;32m--> 635\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno numeric data to plot\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    637\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m numeric_data\u001b[39m.\u001b[39mapply(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_to_ndarray)\n",
      "\u001b[0;31mTypeError\u001b[0m: no numeric data to plot"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdkAAADWCAYAAACdZvhjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKvklEQVR4nO3dMW4caXoG4Pe3J5ukMfCkhkEGHjsyJC18gKESx9rVDcQbLKETGDqCdAMtdQPqAA4oRTYckYCdOJi10Nlio99Bl8ZNqsiuJvtrNnufB2jM6K+u6kJ9+PCyq6vqb733AACb91cPvQMAsK+ELAAUEbIAUETIAkARIQsARYQsABT5buobW2svkrzsvf92nQ9orc2SvE5yMQwd9t5P1tkGADxGK0O2tfZ2+N+DJD/c4TNOkxz33i+H7R201s5678/vsC0AeDRWni7uvR/33o+zCMu1DN9+L78G7LC9y6VlALC3qn+TfZnk08j4WZLj4s8GgAdVHbJHSS5Hxi+TPCv+bAB4UGUhO1zwNEvyZWTxfFgGAHur8pvsyoukhiAGgL00+RaebWqtvUryKkm+//77pz/99NMD7xHstk+fPv2x9/7j2DL9BOu5rZ/WtZMh23t/l+Rdkjx79qyfn58/8B7Bbmut/ddNy/QTrOe2flpX5enisd9ir+i9zws/HwAeVFnIDgE6z+IhFtcdDMsAYG9V38JznvELoA6TfCz+bAB4UNUhe5pk7PGJR0neF382ADyodUJ2llvubW2tXbTWrjzdabjg4qC1drD0vidJvvTeP6y3qwDwuEyZIOBNFuH6uySz1tppFhc1ve29f1566zzjFzv9nOR1a215Fh6TAwCw91aG7NK0dLc+a7j3/vSG8XkSU9sB8BfHpO0AUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFBGyAFBEyAJAESELAEWELAAUEbIAUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFBGyAFBEyAJAESELAEWELAAUEbIAUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFBGyAFBEyAJAESELAEWELAAUEbIAUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFBGyAFBEyAJAESELAEWELAAUEbIAUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFBGyAFBEyAJAESELAEWELAAUEbIAUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFPluyptaa7Mkr5NcDEOHvfeTqR/SWrtI8ibJH4ahoyTPk5z03udTtwMAj8mkkE1ymuS4936ZJK21g9baWe/9+cT1D5K8HV5JcpnkuYAFYJ+tPF3cWnuR5PJrwCbJUti+mPg5J0meZvHt9Wnv/XB5ewCwj6Z8k32Z5Gxk/CzJcZIPUz6o9/55jf0CgEdvyoVPR1mc3r3uMsmzze4OAOyPW0N2uOBpluTLyOL5sGyy1tqT1trROusAwGO16pvsD6s2MATxKr8Zfr+d994/ttbetNZe3bLNV62189ba+S+//DJh88BN9BM8nG3dJ/u29/7h68VOw+0/Jzd9q+29v+u9P+u9P/vxxx+3tIuwn/QTPJythGzv/ePI8Ics7p0FgL20KmTHfou94h73ul4keXLHdQFg590askOAzrN4mMR1B8OyW7XWLta4nxYA9saU08XnGb8A6jDJ2Gng6+ZJxu6RPbxhHAD2wpSQPc3iSU3XHSV5P2H99zc83elF/v8xiwCwd1aGbO/9XZKD1tqvp4xba0+SfOm9X3na03Bq+NO1TXy8frtOa+33WTyq8d3ddx0AdtvUCQJ+TvJ6mE0nWczCM/btdp5rF0v13j+31tJa+3ol8SzJxRqTCwDAozQpZIcLoFZObdd7f3rD+Of4/RWAvzAmbQeAIkIWAIoIWQAoImQBoIiQBYAiQhYAighZACgiZAGgiJAFgCJCFgCKCFkAKCJkAaCIkAWAIkIWAIoIWQAoImQBoIiQBYAiQhYAighZACgiZAGgiJAFgCJCFgCKCFkAKCJkAaCIkAWAIkIWAIoIWQAoImQBoIiQBYAiQhYAighZACgiZAGgiJAFgCJCFgCKCFkAKCJkAaCIkAWAIkIWAIoIWQAoImQBoIiQBYAiQhYAighZACgiZAGgiJAFgCJCFgCKCFkAKCJkAaCIkAWAIkIWAIoIWQAoImQBoIiQBYAiQhYAighZACgiZAGgiJAFgCJCFgCKCFkAKCJkAaCIkAWAIkIWAIoIWQAoImQBoIiQBYAiQhYAighZACjy3ZQ3tdZmSV4nuRiGDnvvJ1M/5L7rA8BjNClkk5wmOe69XyZJa+2gtXbWe3++pfUB4NFZebq4tfYiyeXXgEySpbB8Ub0+ADxWU36TfZnk08j4WZLjLawPAI/SlJA9SnI5Mn6Z5NkW1geAR+nWkB0uWJol+TKyeD4sK1sfAB6zVRc+/bBqA621We99vsn1W2uvkrwa/vnn1tq/r9oOW/U3Sf740DvBFX9/0wL9tPP00+65sZ/WNfXq4q3qvb9L8i5JWmvnvXenlXeImuye1tr5Tcv0025Tk91zWz+ty8MoAKDIqpAd+y31iltOFW9ifQB4tG4N2SEA50kORhYfDMvK1h+8m/AetktNds/Umqjd7lGT3bOxmkw5XXye8QuYDpN8rF5/+D2JHaImu2dqTdRu96jJ7tlkTaaE7GmSsccfHiV5v4X1AeBRWhmyQ6IftNZ+PeXbWnuS5Evv/cPye1trF621T3ddHwD2Seu9r37TxFl0hoD9cv3B/yPr/2OSP6/a3n33h+k2MNPSRZI3Sf4wDB1lcQbjxMVtdzc83/tl7/23t7xnlmu1S/Kv18duqqd+2jz9tJum9NMN681y13r23rf+yuK5xQdL/z5Icrat9b1KatKvvS6Wt+e1dj3eDq+zJJ/uULv/nVpP/VRSP/20Q691+mnT9dz6fbJm9dk9GzqmJ0meZvHX9tPe++Hy9lhP7/24936cxTUNNxqrXZInSf40/Pfr9kbrqZ82Tz/tnqn9NOa+9XyIh1GY1Wf3bOSY9t4/994/9t4/b2zPWGWsdi+T/Fu+rd1YPfXT5umn/XKvej5EyJrVZ/c4po/XWO2OkvxHvq3dWD3VfvMc0/1yr3puNWTN6rN7Nn1MW2tPWmtH990vVhur3dLY/+Tb2s2Xx/TT5umn/bKJem77m+ykWXkK1+dbmzqmvxl+n5j33j+21t4Ms79QZ6x2V8bGarc0pp82Tz/tl3vXcydn4eFRett7//UJXr33k+G+6cvlcWAS/bQnzMLDRtzQ+B+yuNcPWIN+2h/bDlmz+uyeymN6kaXbSNi4sdpdGRur3dKYfto8/bRf7l3PrYZs341ZfViyiWM6nMZyT+WWjdVuaeyf8m3trtRTP22eftovm6jnQ5wuftBZfRh132M6TzJ2L9/hDeNszljtzpP8Xb6t3Vg99dPm6af9cq96PkTImtVn99z3mL6/4Wk0L7J4lBl1xmp3muSf823txuqpnzZPP+2Xe9Vz6yHbzeqzc+5bkyQfr99e0Fr7fRaPIjNX5v3Mcvu9eCdJ/mW5dln85f3XWfrWM9TzH7J4yPmv9NPm6aedNsst/VSROQ91C8/PSV4PM00kixkNxv5SmGf8h+ep6zPdnWvSe//cWktr7euVj7MkF2pyd8OxnCX5XZJZa+00i+P+9tpj9uZJ/jvJ8XLtkvxtrtUzyX9GP22Lftoha/bTRntk0lR3AMD63CcLAEWELAAUEbIAUETIAkARIQsARYQsABQRsgBQRMgCQBEhCwBFhCwAFPk/Z3k2wv2NQFwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 504x252 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rc('font', family='serif', serif='times new roman')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=22)\n",
    "plt.rc('ytick', labelsize=22)\n",
    "mpl.rcParams['patch.linewidth']=0.5 #width of the boundary of legend\n",
    "\n",
    "sgd_marker, sgd_color, sgd_lt, sgd_ms = 's', '#118AB2', '--', 6\n",
    "our_marker, our_color, our_lt, our_ms = 'o', '#DD3497', '-', 5\n",
    "lw = 2.5\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, sharey = True)\n",
    "fig.subplots_adjust(left=0.16, bottom=.24, right=0.98, top=0.9, wspace=0.05, hspace = 0.3) #margin of the figure\n",
    "fig.set_size_inches(7, 3.5) #exact size of the figure\n",
    "\n",
    "for pretrained in [0,1]:\n",
    "    fnn_results[pretrained]['sgd'].plot(ax = ax[pretrained], color = sgd_color, label = 'LoRA', linestyle = sgd_lt, marker = sgd_marker, linewidth = lw, markersize = sgd_ms)\n",
    "    fnn_results[pretrained]['flt'].plot(ax = ax[pretrained], color = our_color, label = 'Tuning Final Layers', linestyle = our_lt, marker = our_marker, linewidth = lw, markersize = our_ms)\n",
    "    ax[pretrained].grid(True)\n",
    "\n",
    "ax[0].set_title('Random', size = 22, y = 1.01)\n",
    "ax[1].set_title('Pretrained', size = 22, y = 1.01)\n",
    "\n",
    "# ax[0].set_ylim(0,0.15)\n",
    "ax[1].legend(fontsize=16, bbox_to_anchor=(1.02,1.01))\n",
    "fig.supxlabel('\\# Tunable Parameters', fontsize = 26)\n",
    "fig.supylabel('MSE', fontsize = 26)\n",
    "    \n",
    "plt.savefig('../figures/flt_approx.pdf')\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fdece8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
